{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API from Quiver Quantitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://api.quiverquant.com/beta/live/congresstrading\"\n",
    "headers = {\"accept\": \"application/json\",\n",
    "\"X-CSRFToken\": \"TyTJwjuEC7VV7mOqZ622haRaaUr0x0Ng4nrwSRFKQs7vdoBcJlK9qjAS69ghzhFu\",\n",
    "\"Authorization\": \"Token 6c270b0b83d71d997f258d06db1dc8ec37cc8790\"}\n",
    "r = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = r.json()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "congress_trading_df = pd.DataFrame(json_data)\n",
    "\n",
    "congress_trading_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Unneeded Variables and Recoding them as Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_trading_df= congress_trading_df.drop(['ReportDate'], axis = 1)\n",
    "\n",
    "import pandas\n",
    "import datetime\n",
    "congress_trading_df['Date'] = pandas.to_datetime(congress_trading_df['TransactionDate'], format='%Y-%m-%d')\n",
    "\n",
    "congress_trading_df= congress_trading_df.drop(['TransactionDate'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating list of Unique Tickers in order to find them on Yahoo! Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "listed_tickers = pandas.read_csv(\"update_unique_ticker_again_1.csv\")\n",
    "\n",
    "listed_tickers= listed_tickers.drop(['Unnamed: 0'], axis = 1)\n",
    "listed_tickers= listed_tickers.drop(['ReportDate'], axis = 1)\n",
    "listed_tickers= listed_tickers.drop(['Index'], axis = 1)\n",
    "\n",
    "import pandas\n",
    "import datetime\n",
    "listed_tickers['Date'] = pandas.to_datetime(listed_tickers['TransactionDate'], format='%Y-%m-%d')\n",
    "\n",
    "listed_tickers= listed_tickers.drop(['TransactionDate'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ticker = listed_tickers['Ticker'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running pandas_datareader to find the Opening Prices for all of the stocks listed in our transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "df = pdr.DataReader(unique_ticker, data_source='yahoo', start='2021-06-29', end='2022-04-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_open = pandas.DataFrame(df['Open'])\n",
    "stock_price_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "stock_price_open.to_csv(\"stock_open.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "new_stock_open = pandas.read_csv(\"stock_open.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "new_stock_open['Date'] = pandas.to_datetime(new_stock_open['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering the list to have newest dates at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_new = new_stock_open\n",
    "df_new = df_new.iloc[::-1]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the Opening Prices with the rest of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_new_open = listed_tickers.merge(new_stock_open, how='left', on='Date').ffill()\n",
    "merge_new_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "merge_new_open.to_csv(\"congress_stock_trade_open_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting only the prices associated with each row, rather than all the prices during the time frame for a specific stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "updating_list_tickers = []\n",
    "for i in range(len(merge_new_open)):\n",
    "    ticker = merge_new_open.iloc[i,0]\n",
    "    y = merge_new_open.filter(items= [ticker])\n",
    "    updating_list_tickers.append(y.loc[i])\n",
    "\n",
    "updating_list_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_tickers['OpenPrice'] = [updating_list_tickers[i][0] for i in range(len(updating_list_tickers))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The steps above are repeated for the next and previous 7 days, along with previous 30 and next 12 (up to current date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code below is an example for the next 7 day open price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas\n",
    "\n",
    "listed_tickers['next_seven_days'] = listed_tickers['Date'] + datetime.timedelta(days = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "df_next_days = pdr.DataReader(unique_ticker, data_source='yahoo', start='2021-07-06', end='2022-04-25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of troubleshooting errors when the DataReader was unable to read some of the tickers (we only had this problem twice and it was only for 3 tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "df_next_days_SHW = pdr.DataReader('SHW', data_source='yahoo', start='2021-07-06', end='2022-04-25')\n",
    "\n",
    "stock_price_open_next_days_SHW = pandas.DataFrame(df_next_days_SHW['Open'])\n",
    "\n",
    "stock_price_open_next_days_SHW.to_csv(\"stock_open_next_SHW.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data after the missing values were replaced with their true open prices associated with the row date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_open_next_days = pandas.DataFrame(df_next_days['Open'])\n",
    "stock_price_open_next_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas\n",
    "stock_price_open_next_days.to_csv(\"stock_open_next.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "new_stock_open_next = pandas.read_csv(\"stock_open_next.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "new_stock_open_next['next_seven_days'] = pandas.to_datetime(new_stock_open_next['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_new_next = new_stock_open_next\n",
    "df_new_next = df_new_next.iloc[::-1]\n",
    "df_new_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating new column that would be moved to the front of the data and allow us to drop the 'Date' variable that is alreadying being used in our main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_next = df_new_next[ ['next_seven_days'] + [ col for col in df_new_next.columns if col != 'next_seven_days']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_next= df_new_next.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the next 7 day open price data with our current transaction data that is being used for final analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merge_new_open_next = listed_tickers.merge(df_new_next, how='left', on='next_seven_days').ffill()\n",
    "merge_new_open_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "merge_new_open_next.to_csv(\"congress_stock_trade_open_next.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "updating_list_tickers_next = []\n",
    "for i_next in range(len(merge_new_open_next)):\n",
    "    ticker_next = merge_new_open_next.iloc[i_next,0]\n",
    "    y_next = merge_new_open_next.filter(items= [ticker_next])\n",
    "    updating_list_tickers_next.append(y_next.loc[i_next])\n",
    "\n",
    "updating_list_tickers_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "listed_tickers['OpenPriceNextSevenDays'] = [updating_list_tickers_next[i_next][0] for i_next in range(len(updating_list_tickers_next))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_tickers.to_csv(\"final_analysis_stock_prices_congress.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the calculated fields to understand the percentage change of a stock for the different time intervals listed previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pandas.read_csv(\"final_analysis_30_day_open_close.csv\")\n",
    "final_df = final_df.drop([\"Unnamed: 0\"], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"next_7_day_percent_change\"] = ((final_df.OpenPriceNextSevenDays - final_df.OpenPrice)/ final_df.OpenPrice)\n",
    "\n",
    "# here are the other calculations that were utilized in our analysis\n",
    "#final_df[\"previous_7_day_percent_change\"] = ((final_df.OpenPrice - final_df.OpenPricePrevSevenDays)/ final_df.OpenPricePrevSevenDays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing of SPY open prices for the same intervals used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "df_spy = pdr.DataReader(\"SPY\", data_source='yahoo', start='2021-06-29', end='2022-04-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spy.to_csv(\"SPY_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "df_spy_next_7_days = pdr.DataReader(\"SPY\", data_source='yahoo', start='2021-07-06', end='2022-04-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spy_next_7_days.to_csv(\"SPY_next_7_days.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined both of the datasets in Excel to have them in centralized location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_historical_price_data = pandas.read_csv(\"SPY_historical_price_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of percentage change of SPY over same time as the next seven day stock open prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_historical_price_data[\"next_7_days_spy_percent_change\"] = ((spy_historical_price_data.OpenPriceNextSevenDays - spy_historical_price_data.OpenPrice)/ spy_historical_price_data.OpenPrice)\n",
    "#spy_historical_price_data[\"prev_7_days_spy_percent_change\"] = ((spy_historical_price_data.OpenPrice - spy_historical_price_data.OpenPricePrevSevenDays)/ spy_historical_price_data.OpenPricePrevSevenDays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating the Purchase and Sale transactions to gain a better insight into how much of a profit/loss would be generated from a purchase and how much the congress member would have profitted/lost if they held the security a week longer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation done in Excel through filtering and creating two new CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_sale = pandas.read_csv(\"transaction_sale.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_purchase = pandas.read_csv(\"transaction_purchase.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilized a google sheet from online to insert the state and party of the associated congress member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to sheet: https://docs.google.com/spreadsheets/d/1tCW1uHhWhfVtZO8Vkflg9GnvQf_eqH2F--HAriZYFqI/edit#gid=1178631925"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used Excel to strip the extra characters in each state\n",
    "### For Example: Alabama's First --> Alabama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_party_state = pandas.read_csv(\"congress_member_state_party.csv\")\n",
    "\n",
    "congress_party_state = congress_party_state.drop([\"Unnamed: 3\"], axis= 1)\n",
    "congress_party_state = congress_party_state.drop([\"Unnamed: 4\"], axis= 1)\n",
    "congress_party_state = congress_party_state.drop([\"Unnamed: 5\"], axis= 1)\n",
    "congress_party_state = congress_party_state.drop([\"Unnamed: 6\"], axis= 1)\n",
    "congress_party_state = congress_party_state.drop([\" \"], axis= 1)\n",
    "\n",
    "congress_party_state['Representative'] = congress_party_state['Full Name']\n",
    "\n",
    "congress_party_state = congress_party_state.drop([\"Full Name\"], axis= 1)\n",
    "\n",
    "merge_party_state = final_df.merge(congress_party_state, how='left', on='Representative').ffill()\n",
    "merge_party_state\n",
    "\n",
    "merge_party_state.to_csv(\"final_with_party_state.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_congress_party_state = pandas.read_csv(\"final_with_party_state.csv\")\n",
    "updated_congress_party_state\n",
    "\n",
    "updated_congress_party_state = updated_congress_party_state.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging SPY prices with the rest of the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_spy_final_df = updated_congress_party_state.merge(spy_historical_price_data, how = 'left', on = 'Date').ffill()\n",
    "merge_spy_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "complete_dataframe = pandas.read_csv(\"merge_spy_final_df_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataframe = complete_dataframe.drop([\"Unnamed: 0\"], axis= 1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
